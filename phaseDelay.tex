\documentclass{sig-alternate}
\usepackage{multirow}
\usepackage{color}
\usepackage{colortbl}
\usepackage{picture}
\usepackage{wrapfig}
\usepackage{algorithm}
\usepackage{graphicx}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}} 
\newcommand{\lucas}[1]{\textcolor{red}{LUCAS: #1}} 
\newcommand{\bill}[1]{\textcolor{blue}{BILL: #1}} 
\newcommand{\carter}[1]{\textcolor{cyan}{CARTER: #1}} 
%\newenvironment{changed}{\par}{\par}

%timm tricks
\newcommand{\bi}{\begin{itemize}[leftmargin=0.4cm]}
\newcommand{\ei}{\end{itemize}}
\newcommand{\be}{\begin{enumerate}}
\newcommand{\ee}{\end{enumerate}}
\newcommand{\tion}[1]{\S\ref{sect:#1}}
\newcommand{\fig}[1]{Figure~\ref{fig:#1}}
\newcommand{\eq}[1]{Equation~\ref{eq:#1}}
 

\usepackage[shortlabels]{enumitem} 
\usepackage{times}
\newcommand{\subparagraph}{}
\usepackage{url}
\def\baselinestretch{1}


\setlist{nosep}
 \usepackage[font={small}]{caption, subfig}
\setlength{\abovecaptionskip}{1ex}
 \setlength{\belowcaptionskip}{1ex}

 \setlength{\floatsep}{1ex}
 \setlength{\textfloatsep}{1ex}
\usepackage[compact,small]{titlesec}
\DeclareMathSizes{7}{7}{7}{7} 
\pagenumbering{arabic}
\setlength{\columnsep}{7mm}

\begin{document}

\conferenceinfo{FSE}{'15 Bergamo, Italy}
\title{Revisiting the Truisms of Software Engineering:\\ Does Phase Delay Dramatically Increases  Repair Time?}
\numberofauthors{3}
\author{
\alignauthor
Tim Menzies, \\Carter Pape\\
       \affaddr{CS, NcState, USA}\\
       tim.menzies@gmail.com,\\carterpape@gmail.com
\alignauthor
William Curtis,\\ Forrest Schull\\
\affaddr{SEI, CMU, USA}
wrn,fjshull@sei.cmu.edu
\alignauthor
Lucas \\Layman\\
       \affaddr{Fraunhofer Center,  USA}\\ 
       llayman@fc-md.umd.edu
} 


 
\maketitle
\begin{abstract}
Does
repair time increases dramatically
the longer a defect persists in a system?
This  is very widely belief and the core rational  for
 rejecting   traditional linear development methods
 in favor of more cyclic agile approaches.

This paper shows that this belief is maintained
quite strongly in the industrial software engineering
community (but, in the academic community, somewhat less so).
Yet based on a sample of 
\carter{230} software projects from around the world from 
\bill{2005 to 2013}, we argue that this belief is mostly 
incorrect. Specifically: the median fix time for issues
is just a few minutes and this increases by a small linear amount
the longer the issue remains in the system. 

What was observed was a small number
of defects that take a remarkably long time to resolve
For these issues, if an issue takes more an hour
to resolve then it will usually require many more hours of work.
These long-tail bugs
are more prevalent the longer a project delays issue removal. 
In order to handle such ``long tail'' issues,
we suggest  augmenting software
development groups with additional ``tiger teams'' that are triggered
when issue resolution time increases beyond a certain number of
minutes.
\end{abstract}

% A category with the (minimum) three required fields
\vspace{1mm}
\noindent
{\bf Categories/Subject Descriptors:} 
D.2.8 [Software Engineering]: Product metrics; 

 

\vspace{1mm}
\noindent
{\bf Keywords:} defect prediction, 

\section{Introduction}
Several recent papers call into questions long-held trusims in the field
of software engineering. Devanbu reports that, in practice, the advantage of types languages
is only very minimal. Nagappan et al. found that XXX, contrary to the advice of Dyketra,
it is not necessarily true that ``goto considered harmful'' XXX. More generally,
several recent  papers comment on ``locality'' effects where effects
thold  generally across XXXX
 
Perhaps it is time to take a look at the base premises of our field, particularly in light of the large software analytics data sets newly available for reseaercehrs.

XXX tsp. 40MB . 235 prokects

\section{Related Work}

In their text Romabach laws

Kent Beck's original extreme programming text is big on this.

Historical  evidence for this dataes back to some studies in the 1970s. To the best of
our knowledge, not updated since. Regardless, as discussed in the next section, this

\input{lucasRelatedWork}

\section{lucasSurvey}

\input{lucas}


\section{billTSP}

\section{carterCharts}

\input{carter}

\section{Data}

\begin{figure}[!t]

%\renewcommand{\baselinestretch}{0.8}
\scriptsize
\begin{center}
\begin{tabular}{r|rrr|ll}
  Sample&\multicolumn{3}{c|}{Percentiles}\\ 
size & 25th & 50th & 75th & Phase injected & Phase removed\\\hline
57& 6& 16& 47&  BeforeDevelopment&Code\\
72& 2& 4& 11&  BeforeDevelopment&CodeInspect\\
165& 6& 18& 56&  BeforeDevelopment&Test\\
50& 6& 20& 37&  BeforeDevelopment&IntTest\\
42& 8& 28& 65&  BeforeDevelopment&SysTest\\\hline

66& 2& 6& 15&  Planning&Planning\\
41& 1& 5& 16&  Planning&ReqtsReview\\\hline

23& 0& 1& 3&  Reqts&Reqts\\
245& 6& 13& 23&  Reqts&ReqtsReview\\
289& 7& 16& 30&  Reqts&ReqtsInspect\\
32& 6& 21& 40&  Reqts&Design\\
49& 2& 7& 24&  Reqts&DesignInspect\\\hline
 

94& 2& 5& 10&  HLD&HLDReview\\
133& 3& 8& 19&  HLD&HLDInspect\\
33& 2& 5& 17&  HLD&Design\\\hline



37& 2& 4& 6&  Design&Design\\
455& 11& 24& 53&  Design&DesignInspect\\
218& 5& 14& 30&  Design&Code\\
166& 4& 11& 22&  Design&CodeInspect\\
542& 14& 31& 60&  Design&Test\\
67& 6& 15& 40&  Design&IntTest\\
92& 10& 25& 53&  Design&SysTest\\\hline

53& 2& 4& 9&  DesignInspect&DesignInspect\\
38& 1& 3& 9&  DesignInspect&Code\\\hline

126& 4& 12& 31&  Code&Code\\
459& 11& 24& 45&  Code&CodeInspect\\
461& 11& 26& 55&  Code&Test\\
348& 10& 26& 62&  Code&IntTest\\
230& 8& 18& 39&  Code&SysTest\\
71& 2& 11& 28&  Code&AcceptTest\\\hline

64& 2& 4& 10&  CodeInspect&CodeInspect\\
57& 2& 5& 13&  CodeInspect&Test\\\hline



110& 3& 10& 23&  Test&Test\\
66& 2& 4& 12&  Test&QualTest\\\hline


32& 1& 2& 4&  IntTest&QualTest\\
36& 1& 11& 30&  IntTest&IntTest\\
21& 1& 2& 5&  IntTest&SysTest\\
 \end{tabular}
\end{center}
\caption{Distribution of fix times seen in SEI TSP data.}
\label{fig:faw}
\end{figure}
 
 
\begin{figure}
\begin{center}
\begin{tabular}{rrl}
year& \# issues&\\\hline
2006 &  44 &\\
2007 &  34 &\\
2008&  288 &\rule{1mm}{2mm}\\
2009&  846 &\rule{3mm}{2mm}\\
2010& 1007 &\rule{3mm}{2mm}\\
2011& 3273 &\rule{10mm}{2mm}\\
2012&18102 &\rule{45mm}{2mm}\\
2013&20336 &\rule{50mm}{2mm}\\
2014& 3307 & \rule{10mm}{2mm}\\\cline{1-2}
Total:&47228
\end{tabular}
\end{center}
\caption{This paper studies 47,228 issues recorded 2006 to 2014.}\label{fig:years}
\end{figure}
\begin{figure*}[!t]
\begin{center}
\includegraphics[width=6in]{waterfall2.png}
\end{center}
\caption{Different approaches to software development:  waterfall and agile (bottom left).}
\end{figure*}


\begin{figure*}[!t]

\renewcommand{\baselinestretch}{0.7} 
\begin{center}
\begin{tabular}{ll|r|rl}
            &                  & Sample\\
Phase injected & Phase removed & size & \multicolumn{2}{l}{Scale up, w.r.t. to first phase}
\input{deltas}
\end{tabular}
\end{center}
\caption{50th percentile (median) scale ups  for  time to resolve issues (taken from \fig{raw}).}
\label{fig:scale}
\end{figure*}



In these results, we checked if a small number of bugs are most expensive. 
To check this:
\bi
\item
We repeated the analysis that generated \fig{scale},
but instead of looking at the 50th percentile, we displayed the scale up factors
\item 
We only
checked the Design and Code scale up results since, from \fig{scale}, it is clear these
have the most examples of longest phase delays.
\ei 
The  results are shown in \fig{scale90} and these
results are somewhat different for Design and Coding issues:
\bi 
\item For Design issues,  these have the same
general form as the 50th percentile results. That is, while it it certainly faster
to remove thing sin the phase where they are created, once we leave that phase
it does not seem to matter much how many phases we wait before fixing the issue.
\begin{itemize}
\item For Coding issues, the seems little impact of phase delay on the time
required to fix.
\end{itemize}


\begin{figure*}[!t]

\renewcommand{\baselinestretch}{0.7} 
\begin{center}
\begin{tabular}{ll|r|rl}
            &                  & Sample\\
Phase injected & Phase removed & size & \multicolumn{2}{l}{Scale up, w.r.t. to first phase}
\input{deltaBig}
\end{tabular}
\end{center}
\caption{90th percentile scale ups  for  time to resolve issues .}
\label{fig:scale90}
\end{figure*}


The data used in this work shirai14


We offer the following notes on the data used in this study.
These notes will be somewhat detailed and we offer them in order
to make the following point:
\bi 
\item The results section of this paper fails to find that  phase delay causing dramatic increases
in time to fix issues;
\item This lack-of-phase-delay effect {\em cannot} be explained away just by  saying that
the projects in this sample adopted something like  agile methods to reduce re-work costs.
\ei  


The Team Software ProcessSM (TSPSM) provides a
framework that teams use to collect software process data in real
time, using a defined disciplined process


\begin{figure}
\begin{center}
\scriptsize\begin{tabular}{|l@{~:~}l|}\hline
Bug Prediction Dataset &http://bug.inf.usi.ch \\
Eclipse Bug Data &http://goo.gl/tYKahN \\
FLOSSMetrics& http://flossmetrics.org \\
FLOSSMole &http://flossmole.org \\
IBSBSG& http://www.isbsg.org \\
ohloh& http://www.openhub.net \\
PROMISE &http://promisedata.googlecode.com \\
Qualitas Corpus &http://qualitascorpus.com \\
Software Artifact Repository &http://sir.unl.edu \\
SourceForge Research Data &http://zerlot.cse.nd.edu \\
Sourcerer Project &http://sourcerer.ics.uci.edu \\
Tukutuku &http://www.metriq.biz/tukutuku \\
Ultimate Debian Database &http://udd.debian.org\\\hline
\end{tabular}
\end{center}
\caption{Some repositories of software engineering data.}\label{fig:sedata}
\end{figure}

\fig{sedata} lists some of the publicly available
software projects data sets currently available to 
SE researchers. Most of the \fig{sedata} data sets have software product information
such as full source code, or summaries of static features.
A subset of that data contain issue or defect reports and/or
the time taken to build these systems. Compared to those data
setss, the SEI TSP data contains much more detailed process details
including a detailed phased breakdown showing what happened at what
phases of the lifecycle. 

As dictacted by the  the projects in our SEI TSP data set  use coaches,
peer review, and  personnel reviews:
a ``coach'' is the team member  authorized to submit project data
(before submission,
these coaches check the data for obvious errors);
``personnel review'' is a technique taken  from the Personal Software
ProcessSM (PSPSM); and
``peer review'' is a standard technique in
traditional software engineering.
PSPSM encourages developers to continually make and review their personnel estimates
about their day-to-day tasks, then compare those estimates against the actual development effort.
In this way, developers can acquire a more realistic understanding of their work behaviour.
As to peer review,  Basili and Boehm write  commented in 2001~\cite{boehm01} 
that peer reviews can catch over half the defects introduced into a system.
Peer review can be conducted on any artifact generated anywhere in the software
lifecycle and can quickly be adapted to new kinds of artifacts.


The phased used in this paper are shown in \fig{waterfall}. Note that, in that figure:
\bi 
\item
Several  phases have the same  sub-activities of {\em review} and {\em inspect}\footnote{\bill{plz distinguish review and inspect. does one usually happen first?}}
\item Testing is divided into several statges \footnote{\bill{need a one
line description of test vs qualtest vs inttest vs systemTest vs AcceptTest. I tries some words in the Key to \fig{sedata}. dont know if i got it right.}}
\ei 
Also shown in \fig{waterfall} (bottom left) is the standard definition of an agile process~\cite{boehmturner03}:
Given some
some backlog of tasks, wgeb teams complete their current tasks, they select the next task(s) to complete. That selection process may use a variety of criteria
to prioritize which  tasks are selected (for more details on that selection process, see~\cite{me09j,port08,boehmturner03}). Tasks are completed in ``sprints'' that can last hours,
days, but rarely not more than weeks. Each day meet for brief ``scrum'' sessions to assess (and possibly alter) their current progress on the goals of the sprint.  
Agile teams race to generate releases
(in the continuous release model, releases can be generated on a daily basis, or even faster).  
Experience gained from those releases informs the discussion in the daily scrums which, in turn,
can inform the team's decisions on how to select and implement the next set of tasks for next sprint.
In fact, that experience can result in changing some/all of the tasks in the current backlog. 

TSP is not antithetical to agile--  indeed a TSP-waterfall style project can adopt aspects
of agile.  For example the agile loop  could be applied
over one or more of the phases shown in the long waterfall chain of \fig{waterfall}. Some
TSP teams adopt something like test-driven-development\footnote{TDD is an agile-method
where the ``test'' is the primary driver of the design. The tests are written first,
then the code to support those tests. TDD proceeds in three steps: red (where there
are broken tests); green (where tests are passing); and, possibly, refactor (where
the code is re-organized based on feedback from those tests~\cite{fraser03}.} where
reviews are scheduled after testing. Some of the groups in the SEI TSP data used that approach but
they do not effect the main conclusions of this paper:
\bi 
\item They were strongly in the minority\bill{any numbers on this?};
\item Most of our phase delay data comes from much early in the waterfall model
of \fig{waterfall}.
\ei 
That said, there are some very ``un-agile'' aspects
of the processes used by the   projects in the TSP SEI data.
For teams to be included in this data set they had to be following certain 
 guidelines
laid down by TSPSM (and SEI staff monitored these projects to ensure that that the
following guidelines were maintained\footnote{bill, can you talk at all about your work doing site visits? i.e. how did you ensure compilance with the following}):
\be 
\item  The TSP projects studied here offer new releases at least every three months, but
often much longer that that\bill{any numbers on that}.
\item The TSP projects studied     spend one day (or more) working on 
\item
The time spent in the of a design activity/phase should require 
approximately as much effort as the coding phase. That is, for the projects
studied here, at least half of the reflection on the requirements, design, code
arises without feedback from running code.
\item The teams
cannot combine development and  testing. That is, as before,
it can be days/weeks
before team members in the TSP SEI datatet gain  feedback from executing code.  
\item The time devoted to ``personnel review'' and ``peer review'' (defined below)
is  about 50\% as much effort as the previous construction phase activity.
\ee 



\section{Data}

The Software Engineering Institute (SEI) at
Carnegie Mellon University has collected data from organizations
that have adopted TSP. 
Our efforts focused on data collected by projects that launched
after 2009 and used an automatic data recording tool. 
Data collected included time logs, defect
logs, added and modified size logs, and work
breakdown strcture logs.
The projects
were mostly small to medium, with a median duration of 46 days
and a maximum duration of 90 days. Median team size was 7
people, with a maximum of 40. Hence,  total development 
effort\footnote{
Effort =  duration*teamSize/workDaysPerYear.} for
these projects ranged from 1.3 years (median) to 14.3 years (max).

In these logs
the log records include work start time, work end time, delta
work time, and interruption time. Software engineers are often
interrupted by meetings, requests for technical help, reporting, and
so forth. These events are recorded, in minutes, as interruption
time. In this paper, when we report ``time to resolve an
issue'', we show the difference between the start and end times
of a work session, with any interruption time subtracted (the
difference in times, minus the interruptions).  

As of January 2014, the SEI TSP database contained data from 109
TSP projects. The projects started between July 2009 and
September 2013; they included 34 teams and 309 people. Among
the database fact tables, the time store contains 103,023 time logs,
18,408 defect logs, and 7,464 size logs\footnote{\bill{we need to 
update this table}}.  

A common property of real-world data sets is the presence
of noisy entries (superfluous  or spurious data). 
The level of noise can be quite high. As reported
in \cite{shepperd12}, around
10\% to 30\%
of the records in the NASA MDP defect data sets are
affected by noise. Nichols et al.~\cite{shirai14}  report that
the noise levesl in the SEI TSE data are smaller than those seen
in other data sets. They found in the SEI TSP data that:\bi 
\item
4\% of the data was incorrect such as  null values of illegal formats;
\item  2\% of the data has inconsistencies such as timestamps
where the stop time was before the start time;
\item 3\% of the data had data that was not credible
such as tasks listed in one day that took like than six hours.
\ei 
That said, certain semantic features of the SEI TSP data should be noted.
Firstly, in the current TSP collection tool, 
fix times are only the developer time for the developer walking through the phases of \fig{waterfall}.
We are currently tracking the fix time for post-release issues (e.g. those raised during  acceptance test and later
product life cycle). So far, in that post-release data,  we have not detected
a dramatic phase escalation effect (but at this time, we have nothing definitive comment on that matter).

\bill{somewhere you have one note on \underline{find} and fix times.  for this paper, we need just fix times. but is there
anything we need to fret about re \underline{find} times?}

The majority of the teams follow a more linear process within a single feature of physical component (usually no more than a week or two work in total). Unlike some agile teams, *most*TSP teams will not conflate development and unit test.

The starting point for this paper were the times required to fix 47,228 issues.
All data was collected
by the Software Engineering Institute in the period 2006 to 2014 (see \fig{years}).
To the best of our knowledge, this is the largest sample of ``time to fix issues''
yet analyzed. 

This data was collected using the   methodology described by
Watts Humphrey's Team Software Process~\cite{tsp00}. TSP is an extension of Humphrey's early
work on Personnel Software Process~\cite{psp05}.  PSP encourages developers to continually make estimates
about their day-to-day tasks, then compare those estimates against the actual development effort
(in this way, developers can acquire a more realistic understanding of their work behaviour).

In all data, was collected from 172 separate projects. Given Beck's comments (above) about phase delay motivating agile processes, we take care to identify the differences of these 
projects to agile development projects. An alternate, more traditional approach is a ``macro linear''
approach such as the ``waterfall methodology'' that develops code after an extensive
pre-planning stage:

\[
\mathit{Reqts}
\mathit{ReqtsReview}
\mathit{ReqtsInspect}

\mathit{HighLevelDesign}
\mathit{HighLevelReview}
\mathit{HighLevelInspect}

\mathit{Design}
\mathit{DesignReview}
\mathit{DesignInspect}

\mathit{Code}

\mathit{Compile}
\mathit{Test}
\mathit{IntTest}
\mathit{SysTest}
\]

In the original paper defining and 
critiquing ``waterfall'', Royce defines a set of assessment and feedback processes
such that 


care to contrast these 
The majority of the teams follow a basically linear process within a single feature of physical component (usually no more than a week or two work in total). Unlike some agile teams, *most*TSP teams will not conflate development and unit test.  This is usually pretty clear from the task  phase sequencing. A few teams choose to follow a Test Driven Development like process in which code review or inspection will follow test. In a more traditional “micro-linear” TSP approach, unit test follows inspections. 


Our data reporting the time required
to resolve issues in phase $j$ that there were introduced in phase $i, i<j$.



The defect typ that we studied were
\be 
\item design, compile, test, or other support system problems = Environment
procedure calls and reference, I/O, user formats = Interface
structure, content = Data
comments, messages = Documentation
spelling, punctuatio typos, instruction formats = Syntax
logic, pointers, loops, recursion, computation, function defects = Function
error messages, inadequate checks = Checking
change management, library, version control = Build, package
declaration, duplicate names, scope, limits = Assignment
configuration, timing, memory = System
\ee
\section{Conclusion}

\section*{Acknowledgements}
This work was partially funded by an National Science
Foundation grant NSF-CISE 1302169.

\clearpage
\vspace*{0.5mm}
\scriptsize
\bibliographystyle{unsrt}
\bibliography{refs} 


\end{document}
